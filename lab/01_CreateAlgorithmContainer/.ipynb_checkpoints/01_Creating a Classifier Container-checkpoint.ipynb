{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a docker container for training/deploying our classifier\n",
    "\n",
    "In this exercise we'll create a Docker image that will have the required code for training and deploying a ML model. In this particular example, we'll use scikit-learn (https://scikit-learn.org/) and the **Random Forest Tree** implementation of that library to train a flower classifier. The dataset used in this experiment is a toy dataset called Iris (http://archive.ics.uci.edu/ml/datasets/iris). The clallenge itself is very basic, so you can focus on the mechanics and the features of this automated environment.\n",
    "\n",
    "A first pipeline will be executed at the end of this exercise, automatically. It will get the assets you'll push to a Git repo, build this image and push it to ECR, a docker image repository, used by SageMaker.\n",
    "\n",
    "> **Question**: Why would I create a Scikit-learn container from scratch if SageMaker already offerst one (https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html).  \n",
    "> **Answer**: This is an exercise and the idea here is also to show you how you can create your own container. In a real-life scenario, the best approach is to use the native container offered by SageMaker.\n",
    "\n",
    "\n",
    "## Why do I have to do this? If you're asking yourself this question you probably don't need to create a custom conainer. If that is the case, you can skip this section by clicking on the link bellow and use the built-in container with XGBoost to run the automated pipeline\n",
    "> [Skip this section](../02_TrainYourModel/01_Training%20our%20model.ipynb) and start training your ML model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - Creating the assets required to build/test a docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Let's start by creating the training script!\n",
    "\n",
    "As you can see, this is a very basic example of Scikit-Learn. Nothing fancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    files = [ os.path.join(path, file) for file in os.listdir(path) ]\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        raise ValueError(\"Invalid # of files in dir: {}\".format(path))\n",
    "\n",
    "    raw_data = [ pd.read_csv(file, sep=\",\", header=None ) for file in files ]\n",
    "    data = pd.concat(raw_data)\n",
    "\n",
    "    # labels are in the first column\n",
    "    y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]\n",
    "    return X,y\n",
    "    \n",
    "def start(args):\n",
    "    print(\"Training mode\")\n",
    "\n",
    "    try:\n",
    "        X_train, y_train = load_dataset(args.train)\n",
    "        X_test, y_test = load_dataset(args.validation)\n",
    "        \n",
    "        hyperparameters = {\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"verbose\": 1, # show all logs\n",
    "            \"n_jobs\": args.n_jobs,\n",
    "            \"n_estimators\": args.n_estimators\n",
    "        }\n",
    "        print(\"Training the classifier\")\n",
    "        model = RandomForestClassifier()\n",
    "        model.set_params(**hyperparameters)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Score: {}\".format( model.score(X_test, y_test)) )\n",
    "        joblib.dump(model, open(os.path.join(args.model_dir, \"iris_model.pkl\"), \"wb\"))\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, \"failure\"), \"w\") as s:\n",
    "            s.write(\"Exception during training: \" + str(e) + \"\\\\n\" + trc)\n",
    "            \n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print(\"Exception during training: \" + str(e) + \"\\\\n\" + trc, file=sys.stderr)\n",
    "        \n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ok. Lets then create the handler. The **Inference Handler** is how we use the SageMaker Inference Toolkit to encapsulate our code and expose it as a SageMaker container.\n",
    "SageMaker Inference Toolkit: https://github.com/aws/sagemaker-inference-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile handler.py\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from sagemaker_inference.default_inference_handler import DefaultInferenceHandler\n",
    "from sagemaker_inference.default_handler_service import DefaultHandlerService\n",
    "from sagemaker_inference import content_types, errors, transformer, encoder, decoder\n",
    "\n",
    "class HandlerService(DefaultHandlerService, DefaultInferenceHandler):\n",
    "    def __init__(self):\n",
    "        op = transformer.Transformer(default_inference_handler=self)\n",
    "        super(HandlerService, self).__init__(transformer=op)\n",
    "    \n",
    "    ## Loads the model from the disk\n",
    "    def default_model_fn(self, model_dir):\n",
    "        model_filename = os.path.join(model_dir, \"iris_model.pkl\")\n",
    "        return joblib.load(open(model_filename, \"rb\"))\n",
    "    \n",
    "    ## Parse and check the format of the input data\n",
    "    def default_input_fn(self, input_data, content_type):\n",
    "        if content_type != \"text/csv\":\n",
    "            raise Exception(\"Invalid content-type: %s\" % content_type)\n",
    "        return decoder.decode(input_data, content_type).reshape(1,-1)\n",
    "    \n",
    "    ## Run our model and do the prediction\n",
    "    def default_predict_fn(self, payload, model):\n",
    "        return model.predict( payload ).tolist()\n",
    "    \n",
    "    ## Gets the prediction output and format it to be returned to the user\n",
    "    def default_output_fn(self, prediction, accept):\n",
    "        if accept != \"text/csv\":\n",
    "            raise Exception(\"Invalid accept: %s\" % accept)\n",
    "        return encoder.encode(prediction, accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Now we need to create the entrypoint of our container. The main function\n",
    "\n",
    "We'll use **SageMaker Training Toolkit** (https://github.com/aws/sagemaker-training-toolkit) to work with the arguments and environment variables defined by SageMaker. This library will make our code simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import train\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "from sagemaker_inference import model_server\n",
    "from sagemaker_training import environment\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2 or ( not sys.argv[1] in [ \"serve\", \"train\" ] ):\n",
    "        raise Exception(\"Invalid argument: you must inform 'train' for training mode or 'serve' predicting mode\") \n",
    "        \n",
    "    if sys.argv[1] == \"train\":\n",
    "        \n",
    "        env = environment.Environment()\n",
    "        \n",
    "        parser = argparse.ArgumentParser()\n",
    "        # https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md\n",
    "        parser.add_argument(\"--max-depth\", type=int, default=10)\n",
    "        parser.add_argument(\"--n-jobs\", type=int, default=env.num_cpus)\n",
    "        parser.add_argument(\"--n-estimators\", type=int, default=120)\n",
    "        \n",
    "        # reads input channels training and testing from the environment variables\n",
    "        parser.add_argument(\"--train\", type=str, default=env.channel_input_dirs[\"train\"])\n",
    "        parser.add_argument(\"--validation\", type=str, default=env.channel_input_dirs[\"validation\"])\n",
    "\n",
    "        parser.add_argument(\"--model-dir\", type=str, default=env.model_dir)\n",
    "        \n",
    "        args,unknown = parser.parse_known_args()\n",
    "        train.start(args)\n",
    "    else:\n",
    "        model_server.start_model_server(handler_service=\"serving.handler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Then, we can create the Dockerfile\n",
    "Just pay attention to the packages we'll install in our container. Here, we'll use **SageMaker Inference Toolkit** (https://github.com/aws/sagemaker-inference-toolkit) and **SageMaker Training Toolkit** (https://github.com/aws/sagemaker-training-toolkit) to prepare the container for training/serving our model. **By serving** you can understand: exposing our model as a webservice that can be called through an api call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.7-buster\n",
    "\n",
    "# Set a docker label to advertise multi-model support on the container\n",
    "LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "# Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
    "RUN rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
    "RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "COPY main.py /opt/ml/code/main.py\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "COPY handler.py /opt/ml/code/serving/handler.py\n",
    "\n",
    "ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Finally, let's create the buildspec\n",
    "This file will be used by CodeBuild for creating our Container image.  \n",
    "With this file, CodeBuild will run the \"docker build\" command, using the assets we created above, and deploy the image to the Registry.  \n",
    "As you can see, each command is a bash command that will be executed from inside a Linux Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - Local Test: Let's build the image locally and do some tests\n",
    "### 2.1 Building the image locally, first\n",
    "Each SageMaker Jupyter Notebook already has a **docker** envorinment pre-installed. So we can play with Docker containers just using the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon   68.1kB\n",
      "Step 1/14 : FROM python:3.7-buster\n",
      "3.7-buster: Pulling from library/python\n",
      "\n",
      "\u001b[1B1a1f1ad8: Pulling fs layer \n",
      "\u001b[1B26169501: Pulling fs layer \n",
      "\u001b[1B8a55c3f3: Pulling fs layer \n",
      "\u001b[1Bc9932170: Pulling fs layer \n",
      "\u001b[1Bdb15f518: Pulling fs layer \n",
      "\u001b[1B8947ed83: Pulling fs layer \n",
      "\u001b[1Be7938097: Pulling fs layer \n",
      "\u001b[1B43f425e0: Pulling fs layer \n",
      "\u001b[1B0f3f5863: Pull complete .12MB/2.12MBBB\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:4ab6a7310fe1b1b86653faea184ec55aa58efba2a86f14de6ed995388fe7d99d\n",
      "Status: Downloaded newer image for python:3.7-buster\n",
      " ---> 11c6e5fd966a\n",
      "Step 2/14 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      " ---> Running in faad404a905e\n",
      "Removing intermediate container faad404a905e\n",
      " ---> 5618e13e8c0b\n",
      "Step 3/14 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Running in f2fb85a71e56\n",
      "Removing intermediate container f2fb85a71e56\n",
      " ---> ee66084c363a\n",
      "Step 4/14 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      " ---> Running in 7c0acf13c865\n",
      "Get:1 http://deb.debian.org/debian buster InRelease [121 kB]\n",
      "Get:2 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]\n",
      "Get:3 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]\n",
      "Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [234 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7906 kB]\n",
      "Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages [7868 B]\n",
      "Fetched 8387 kB in 2s (5354 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java default-jdk-headless default-jre default-jre-headless\n",
      "  java-common libasound2 libasound2-data libavahi-client3 libavahi-common-data\n",
      "  libavahi-common3 libcups2 libdbus-1-3 libdrm-amdgpu1 libdrm-common\n",
      "  libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libgif7 libgl1\n",
      "  libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm7\n",
      "  libnspr4 libnss3 libpciaccess0 libpcsclite1 libsensors-config libsensors5\n",
      "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
      "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxtst6\n",
      "  libxxf86vm1 openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
      "  openjdk-11-jre-headless\n",
      "Suggested packages:\n",
      "  libasound2-plugins alsa-utils cups-common pciutils pcscd lm-sensors\n",
      "  openjdk-11-demo openjdk-11-source visualvm libnss-mdns fonts-dejavu-extra\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  | fonts-wqy-zenhei fonts-indic\n",
      "Recommended packages:\n",
      "  dbus libatk-wrapper-java-jni fonts-dejavu-extra\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java default-jdk default-jdk-headless default-jre\n",
      "  default-jre-headless java-common libasound2 libasound2-data libavahi-client3\n",
      "  libavahi-common-data libavahi-common3 libcups2 libdbus-1-3 libdrm-amdgpu1\n",
      "  libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libgif7\n",
      "  libgl1 libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm7\n",
      "  libnspr4 libnss3 libpciaccess0 libpcsclite1 libsensors-config libsensors5\n",
      "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
      "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxtst6\n",
      "  libxxf86vm1 openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
      "  openjdk-11-jre-headless\n",
      "0 upgraded, 49 newly installed, 0 to remove and 7 not upgraded.\n",
      "Need to get 279 MB of archives.\n",
      "After this operation, 621 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 java-common all 0.71 [14.4 kB]\n",
      "Get:2 http://deb.debian.org/debian buster/main amd64 libavahi-common-data amd64 0.7-4+b1 [122 kB]\n",
      "Get:3 http://deb.debian.org/debian buster/main amd64 libavahi-common3 amd64 0.7-4+b1 [54.6 kB]\n",
      "Get:4 http://deb.debian.org/debian buster/main amd64 libdbus-1-3 amd64 1.12.20-0+deb10u1 [215 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 libavahi-client3 amd64 0.7-4+b1 [58.1 kB]\n",
      "Get:6 http://deb.debian.org/debian buster/main amd64 libcups2 amd64 2.2.10-6+deb10u3 [324 kB]\n",
      "Get:7 http://deb.debian.org/debian buster/main amd64 libnspr4 amd64 2:4.20-1 [112 kB]\n",
      "Get:8 http://deb.debian.org/debian buster/main amd64 libnss3 amd64 2:3.42.1-1+deb10u3 [1159 kB]\n",
      "Get:9 http://deb.debian.org/debian buster/main amd64 libasound2-data all 1.1.8-1 [59.6 kB]\n",
      "Get:10 http://deb.debian.org/debian buster/main amd64 libasound2 amd64 1.1.8-1 [361 kB]\n",
      "Get:11 http://deb.debian.org/debian buster/main amd64 libpcsclite1 amd64 1.8.24-1 [58.5 kB]\n",
      "Get:12 http://deb.debian.org/debian buster/main amd64 libxi6 amd64 2:1.7.9-1 [82.6 kB]\n",
      "Get:13 http://deb.debian.org/debian buster/main amd64 libxtst6 amd64 2:1.2.3-1 [27.8 kB]\n",
      "Get:14 http://deb.debian.org/debian buster/main amd64 openjdk-11-jre-headless amd64 11.0.8+10-1~deb10u1 [37.4 MB]\n",
      "Get:15 http://deb.debian.org/debian buster/main amd64 default-jre-headless amd64 2:1.11-71 [10.9 kB]\n",
      "Get:16 http://deb.debian.org/debian buster/main amd64 ca-certificates-java all 20190405 [15.7 kB]\n",
      "Get:17 http://deb.debian.org/debian buster/main amd64 libglvnd0 amd64 1.1.0-1 [48.6 kB]\n",
      "Get:18 http://deb.debian.org/debian buster/main amd64 libdrm-common all 2.4.97-1 [13.8 kB]\n",
      "Get:19 http://deb.debian.org/debian buster/main amd64 libdrm2 amd64 2.4.97-1 [39.7 kB]\n",
      "Get:20 http://deb.debian.org/debian buster/main amd64 libglapi-mesa amd64 18.3.6-2+deb10u1 [66.3 kB]\n",
      "Get:21 http://deb.debian.org/debian buster/main amd64 libx11-xcb1 amd64 2:1.6.7-1+deb10u1 [190 kB]\n",
      "Get:22 http://deb.debian.org/debian buster/main amd64 libxcb-dri2-0 amd64 1.13.1-2 [101 kB]\n",
      "Get:23 http://deb.debian.org/debian buster/main amd64 libxcb-dri3-0 amd64 1.13.1-2 [100 kB]\n",
      "Get:24 http://deb.debian.org/debian buster/main amd64 libxcb-glx0 amd64 1.13.1-2 [116 kB]\n",
      "Get:25 http://deb.debian.org/debian buster/main amd64 libxcb-present0 amd64 1.13.1-2 [99.1 kB]\n",
      "Get:26 http://deb.debian.org/debian buster/main amd64 libxcb-sync1 amd64 1.13.1-2 [103 kB]\n",
      "Get:27 http://deb.debian.org/debian buster/main amd64 libxfixes3 amd64 1:5.0.3-1 [21.9 kB]\n",
      "Get:28 http://deb.debian.org/debian buster/main amd64 libxdamage1 amd64 1:1.1.4-3+b3 [14.9 kB]\n",
      "Get:29 http://deb.debian.org/debian buster/main amd64 libxshmfence1 amd64 1.3-1 [8820 B]\n",
      "Get:30 http://deb.debian.org/debian buster/main amd64 libxxf86vm1 amd64 1:1.1.4-1+b2 [20.8 kB]\n",
      "Get:31 http://deb.debian.org/debian buster/main amd64 libdrm-amdgpu1 amd64 2.4.97-1 [27.3 kB]\n",
      "Get:32 http://deb.debian.org/debian buster/main amd64 libpciaccess0 amd64 0.14-1 [53.5 kB]\n",
      "Get:33 http://deb.debian.org/debian buster/main amd64 libdrm-intel1 amd64 2.4.97-1 [69.8 kB]\n",
      "Get:34 http://deb.debian.org/debian buster/main amd64 libdrm-nouveau2 amd64 2.4.97-1 [26.3 kB]\n",
      "Get:35 http://deb.debian.org/debian buster/main amd64 libdrm-radeon1 amd64 2.4.97-1 [31.1 kB]\n",
      "Get:36 http://deb.debian.org/debian buster/main amd64 libllvm7 amd64 1:7.0.1-8+deb10u2 [13.1 MB]\n",
      "Get:37 http://deb.debian.org/debian buster/main amd64 libsensors-config all 1:3.5.0-3 [31.6 kB]\n",
      "Get:38 http://deb.debian.org/debian buster/main amd64 libsensors5 amd64 1:3.5.0-3 [52.6 kB]\n",
      "Get:39 http://deb.debian.org/debian buster/main amd64 libgl1-mesa-dri amd64 18.3.6-2+deb10u1 [6685 kB]\n",
      "Get:40 http://deb.debian.org/debian buster/main amd64 libglx-mesa0 amd64 18.3.6-2+deb10u1 [180 kB]\n",
      "Get:41 http://deb.debian.org/debian buster/main amd64 libglx0 amd64 1.1.0-1 [30.0 kB]\n",
      "Get:42 http://deb.debian.org/debian buster/main amd64 libgl1 amd64 1.1.0-1 [91.1 kB]\n",
      "Get:43 http://deb.debian.org/debian buster/main amd64 libgif7 amd64 5.1.4-3 [43.3 kB]\n",
      "Get:44 http://deb.debian.org/debian buster/main amd64 openjdk-11-jre amd64 11.0.8+10-1~deb10u1 [34.2 kB]\n",
      "Get:45 http://deb.debian.org/debian buster/main amd64 default-jre amd64 2:1.11-71 [1044 B]\n",
      "Get:46 http://deb.debian.org/debian buster/main amd64 openjdk-11-jdk-headless amd64 11.0.8+10-1~deb10u1 [215 MB]\n",
      "Get:47 http://deb.debian.org/debian buster/main amd64 default-jdk-headless amd64 2:1.11-71 [1104 B]\n",
      "Get:48 http://deb.debian.org/debian buster/main amd64 openjdk-11-jdk amd64 11.0.8+10-1~deb10u1 [2635 kB]\n",
      "Get:49 http://deb.debian.org/debian buster/main amd64 default-jdk amd64 2:1.11-71 [1056 B]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 279 MB in 5s (54.3 MB/s)\n",
      "Selecting previously unselected package java-common.\n",
      "(Reading database ... 24604 files and directories currently installed.)\n",
      "Preparing to unpack .../00-java-common_0.71_all.deb ...\n",
      "Unpacking java-common (0.71) ...\n",
      "Selecting previously unselected package libavahi-common-data:amd64.\n",
      "Preparing to unpack .../01-libavahi-common-data_0.7-4+b1_amd64.deb ...\n",
      "Unpacking libavahi-common-data:amd64 (0.7-4+b1) ...\n",
      "Selecting previously unselected package libavahi-common3:amd64.\n",
      "Preparing to unpack .../02-libavahi-common3_0.7-4+b1_amd64.deb ...\n",
      "Unpacking libavahi-common3:amd64 (0.7-4+b1) ...\n",
      "Selecting previously unselected package libdbus-1-3:amd64.\n",
      "Preparing to unpack .../03-libdbus-1-3_1.12.20-0+deb10u1_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Selecting previously unselected package libavahi-client3:amd64.\n",
      "Preparing to unpack .../04-libavahi-client3_0.7-4+b1_amd64.deb ...\n",
      "Unpacking libavahi-client3:amd64 (0.7-4+b1) ...\n",
      "Selecting previously unselected package libcups2:amd64.\n",
      "Preparing to unpack .../05-libcups2_2.2.10-6+deb10u3_amd64.deb ...\n",
      "Unpacking libcups2:amd64 (2.2.10-6+deb10u3) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../06-libnspr4_2%3a4.20-1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.20-1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../07-libnss3_2%3a3.42.1-1+deb10u3_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.42.1-1+deb10u3) ...\n",
      "Selecting previously unselected package libasound2-data.\n",
      "Preparing to unpack .../08-libasound2-data_1.1.8-1_all.deb ...\n",
      "Unpacking libasound2-data (1.1.8-1) ...\n",
      "Selecting previously unselected package libasound2:amd64.\n",
      "Preparing to unpack .../09-libasound2_1.1.8-1_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.1.8-1) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../10-libpcsclite1_1.8.24-1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (1.8.24-1) ...\n",
      "Selecting previously unselected package libxi6:amd64.\n",
      "Preparing to unpack .../11-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
      "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../12-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
      "Preparing to unpack .../13-openjdk-11-jre-headless_11.0.8+10-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre-headless:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jre-headless.\n",
      "Preparing to unpack .../14-default-jre-headless_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jre-headless (2:1.11-71) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../15-ca-certificates-java_20190405_all.deb ...\n",
      "Unpacking ca-certificates-java (20190405) ...\n",
      "Selecting previously unselected package libglvnd0:amd64.\n",
      "Preparing to unpack .../16-libglvnd0_1.1.0-1_amd64.deb ...\n",
      "Unpacking libglvnd0:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../17-libdrm-common_2.4.97-1_all.deb ...\n",
      "Unpacking libdrm-common (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../18-libdrm2_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../19-libglapi-mesa_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../20-libx11-xcb1_2%3a1.6.7-1+deb10u1_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.6.7-1+deb10u1) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../21-libxcb-dri2-0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../22-libxcb-dri3-0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../23-libxcb-glx0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../24-libxcb-present0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../25-libxcb-sync1_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../26-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Selecting previously unselected package libxdamage1:amd64.\n",
      "Preparing to unpack .../27-libxdamage1_1%3a1.1.4-3+b3_amd64.deb ...\n",
      "Unpacking libxdamage1:amd64 (1:1.1.4-3+b3) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../28-libxshmfence1_1.3-1_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.3-1) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../29-libxxf86vm1_1%3a1.1.4-1+b2_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../30-libdrm-amdgpu1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../31-libpciaccess0_0.14-1_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.14-1) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../32-libdrm-intel1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../33-libdrm-nouveau2_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../34-libdrm-radeon1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libllvm7:amd64.\n",
      "Preparing to unpack .../35-libllvm7_1%3a7.0.1-8+deb10u2_amd64.deb ...\n",
      "Unpacking libllvm7:amd64 (1:7.0.1-8+deb10u2) ...\n",
      "Selecting previously unselected package libsensors-config.\n",
      "Preparing to unpack .../36-libsensors-config_1%3a3.5.0-3_all.deb ...\n",
      "Unpacking libsensors-config (1:3.5.0-3) ...\n",
      "Selecting previously unselected package libsensors5:amd64.\n",
      "Preparing to unpack .../37-libsensors5_1%3a3.5.0-3_amd64.deb ...\n",
      "Unpacking libsensors5:amd64 (1:3.5.0-3) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../38-libgl1-mesa-dri_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libglx-mesa0:amd64.\n",
      "Preparing to unpack .../39-libglx-mesa0_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libglx-mesa0:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libglx0:amd64.\n",
      "Preparing to unpack .../40-libglx0_1.1.0-1_amd64.deb ...\n",
      "Unpacking libglx0:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libgl1:amd64.\n",
      "Preparing to unpack .../41-libgl1_1.1.0-1_amd64.deb ...\n",
      "Unpacking libgl1:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libgif7:amd64.\n",
      "Preparing to unpack .../42-libgif7_5.1.4-3_amd64.deb ...\n",
      "Unpacking libgif7:amd64 (5.1.4-3) ...\n",
      "Selecting previously unselected package openjdk-11-jre:amd64.\n",
      "Preparing to unpack .../43-openjdk-11-jre_11.0.8+10-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jre.\n",
      "Preparing to unpack .../44-default-jre_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jre (2:1.11-71) ...\n",
      "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
      "Preparing to unpack .../45-openjdk-11-jdk-headless_11.0.8+10-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk-headless:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jdk-headless.\n",
      "Preparing to unpack .../46-default-jdk-headless_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jdk-headless (2:1.11-71) ...\n",
      "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
      "Preparing to unpack .../47-openjdk-11-jdk_11.0.8+10-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jdk.\n",
      "Preparing to unpack .../48-default-jdk_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jdk (2:1.11-71) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.13.1-2) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.6.7-1+deb10u1) ...\n",
      "Setting up libpciaccess0:amd64 (0.14-1) ...\n",
      "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
      "Setting up java-common (0.71) ...\n",
      "Setting up libglvnd0:amd64 (1.1.0-1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Setting up libxcb-glx0:amd64 (1.13.1-2) ...\n",
      "Setting up libsensors-config (1:3.5.0-3) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\n",
      "Setting up libxcb-present0:amd64 (1.13.1-2) ...\n",
      "Setting up libasound2-data (1.1.8-1) ...\n",
      "Setting up libnspr4:amd64 (2:4.20-1) ...\n",
      "Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Setting up libxcb-sync1:amd64 (1.13.1-2) ...\n",
      "Setting up libavahi-common-data:amd64 (0.7-4+b1) ...\n",
      "Setting up libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Setting up libpcsclite1:amd64 (1.8.24-1) ...\n",
      "Setting up libsensors5:amd64 (1:3.5.0-3) ...\n",
      "Setting up libglapi-mesa:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.13.1-2) ...\n",
      "Setting up libgif7:amd64 (5.1.4-3) ...\n",
      "Setting up libxshmfence1:amd64 (1.3-1) ...\n",
      "Setting up libasound2:amd64 (1.1.8-1) ...\n",
      "Setting up libllvm7:amd64 (1:7.0.1-8+deb10u2) ...\n",
      "Setting up libdrm-common (2.4.97-1) ...\n",
      "Setting up libxdamage1:amd64 (1:1.1.4-3+b3) ...\n",
      "Setting up libavahi-common3:amd64 (0.7-4+b1) ...\n",
      "Setting up libnss3:amd64 (2:3.42.1-1+deb10u3) ...\n",
      "Setting up libdrm2:amd64 (2.4.97-1) ...\n",
      "Setting up libavahi-client3:amd64 (0.7-4+b1) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.97-1) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libcups2:amd64 (2.2.10-6+deb10u3) ...\n",
      "Setting up libglx-mesa0:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libglx0:amd64 (1.1.0-1) ...\n",
      "Setting up libgl1:amd64 (1.1.0-1) ...\n",
      "Setting up ca-certificates-java (20190405) ...\n",
      "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
      "Adding debian:QuoVadis_Root_CA.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:Trustis_FPS_Root_CA.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:DST_Root_CA_X3.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:Taiwan_GRCA.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:Sonera_Class_2_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GA_CA.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:LuxTrust_Global_Root_2.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:Verisign_Class_3_Public_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:EE_Certification_Centre_Root_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G2.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:GeoTrust_Universal_CA_2.pem\n",
      "done.\n",
      "Setting up default-jre-headless (2:1.11-71) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for libc-bin (2.28-10) ...\n",
      "Processing triggers for ca-certificates (20200601~deb10u1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Processing triggers for mime-support (3.62) ...\n",
      "Setting up openjdk-11-jre-headless:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up openjdk-11-jre:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "Setting up openjdk-11-jdk-headless:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
      "Setting up default-jre (2:1.11-71) ...\n",
      "Setting up default-jdk-headless (2:1.11-71) ...\n",
      "Setting up openjdk-11-jdk:amd64 (11.0.8+10-1~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Setting up default-jdk (2:1.11-71) ...\n",
      "Removing intermediate container 7c0acf13c865\n",
      " ---> 94260535e79b\n",
      "Step 5/14 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 2405f1eb60cb\n",
      "Removing intermediate container 2405f1eb60cb\n",
      " ---> bfc973de88cd\n",
      "Step 6/14 : RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
      " ---> Running in 92906ff45a6a\n",
      "Collecting multi-model-server\n",
      "  Downloading multi_model_server-1.1.2-py2.py3-none-any.whl (4.9 MB)\n",
      "Collecting sagemaker-inference\n",
      "  Downloading sagemaker_inference-1.5.2.tar.gz (18 kB)\n",
      "Collecting sagemaker-training\n",
      "  Downloading sagemaker_training-3.6.2.tar.gz (40 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.7.2.tar.gz (460 kB)\n",
      "Collecting model-archiver\n",
      "  Downloading model_archiver-1.0.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting retrying==1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.15.7-py2.py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/site-packages (from sagemaker-training) (20.2.3)\n",
      "Collecting gevent\n",
      "  Downloading gevent-20.9.0-cp37-cp37m-manylinux2010_x86_64.whl (5.5 MB)\n",
      "Collecting inotify_simple==1.2.1\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "Collecting werkzeug>=0.15.5\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting paramiko>=2.4.2\n",
      "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
      "Collecting protobuf>=3.1\n",
      "  Downloading protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.19.0,>=1.18.7\n",
      "  Downloading botocore-1.18.7-py2.py3-none-any.whl (6.6 MB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.1.0-cp37-cp37m-manylinux2010_x86_64.whl (235 kB)\n",
      "Collecting greenlet>=0.4.17; platform_python_implementation == \"CPython\"\n",
      "  Downloading greenlet-0.4.17-cp37-cp37m-manylinux1_x86_64.whl (45 kB)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from gevent->sagemaker-training) (50.3.0)\n",
      "Collecting cryptography>=2.5\n",
      "  Downloading cryptography-3.1.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\"\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.3-cp37-cp37m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: sagemaker-inference, sagemaker-training, psutil, future, retrying, inotify-simple\n",
      "  Building wheel for sagemaker-inference (setup.py): started\n",
      "  Building wheel for sagemaker-inference (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-inference: filename=sagemaker_inference-1.5.2-py2.py3-none-any.whl size=26859 sha256=3a6eef4624bb72741e8c02f16c71e8deafe7af70364fffbb238b7b866f0a8783\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n1rxxey/wheels/0e/af/92/39f50f85a12db486c6373fa14b03eb886b2fd5cb389ab09a7d\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-training: filename=sagemaker_training-3.6.2-cp37-cp37m-linux_x86_64.whl size=70979 sha256=b406e766c3b98b102fb082f5c0cc8f4b0e467fa7a66d44daaf58a3c377ac3955\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n1rxxey/wheels/0a/48/0b/b46b1798e095ef99ddaaea2637da0411272367842fbd41e1b6\n",
      "  Building wheel for psutil (setup.py): started\n",
      "  Building wheel for psutil (setup.py): finished with status 'done'\n",
      "  Created wheel for psutil: filename=psutil-5.7.2-cp37-cp37m-linux_x86_64.whl size=288294 sha256=cec43f41ee067494373fef08ab90aa2cb594badb00b5141a95ff7457d05e4248\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n1rxxey/wheels/2d/43/97/00701864a7bee6d9e1a52dd682537dcbf1d013d0e2e6f0c1f1\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=d6dc3a9380bf0a70d428809d13f1055977ef0227fde1684f12c56307d4fdd697\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n1rxxey/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=46a41a844f070c2da8331be5cdef1e594f2f0558478a3ed44e290efd85c12e0d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n1rxxey/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "  Building wheel for inotify-simple (setup.py): started\n",
      "  Building wheel for inotify-simple (setup.py): finished with status 'done'\n",
      "  Created wheel for inotify-simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8203 sha256=d3234f4c858a5b30cc84bec6429e90bd1104747e981d444188a55492de725ce7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n1rxxey/wheels/ef/7e/4a/bfeb3216a60ab5e077958f5a1e980cc3de9663155cfb31c660\n",
      "Successfully built sagemaker-inference sagemaker-training psutil future retrying inotify-simple\n",
      "Installing collected packages: psutil, enum-compat, future, model-archiver, Pillow, multi-model-server, numpy, six, retrying, scipy, sagemaker-inference, urllib3, jmespath, python-dateutil, botocore, s3transfer, boto3, zope.interface, greenlet, zope.event, gevent, inotify-simple, werkzeug, pycparser, cffi, cryptography, bcrypt, pynacl, paramiko, protobuf, sagemaker-training\n",
      "Successfully installed Pillow-7.2.0 bcrypt-3.2.0 boto3-1.15.7 botocore-1.18.7 cffi-1.14.3 cryptography-3.1.1 enum-compat-0.0.3 future-0.18.2 gevent-20.9.0 greenlet-0.4.17 inotify-simple-1.2.1 jmespath-0.10.0 model-archiver-1.0.3 multi-model-server-1.1.2 numpy-1.19.2 paramiko-2.7.2 protobuf-3.13.0 psutil-5.7.2 pycparser-2.20 pynacl-1.4.0 python-dateutil-2.8.1 retrying-1.3.3 s3transfer-0.3.3 sagemaker-inference-1.5.2 sagemaker-training-3.6.2 scipy-1.5.2 six-1.15.0 urllib3-1.25.10 werkzeug-1.0.1 zope.event-4.5.0 zope.interface-5.1.0\n",
      "Removing intermediate container 92906ff45a6a\n",
      " ---> 8736c34a8910\n",
      "Step 7/14 : RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
      " ---> Running in 9ae85185c846\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.19.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (1.5.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pandas, joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-0.16.0 pandas-1.1.2 pytz-2020.1 scikit-learn-0.23.2 threadpoolctl-2.1.0\n",
      "Removing intermediate container 9ae85185c846\n",
      " ---> 39928774f8a5\n",
      "Step 8/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in daec441e8de2\n",
      "Removing intermediate container daec441e8de2\n",
      " ---> 273e37dbac72\n",
      "Step 9/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in be3b6d04ede6\n",
      "Removing intermediate container be3b6d04ede6\n",
      " ---> 61ee59363f05\n",
      "Step 10/14 : ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in d9ed01b6ac0a\n",
      "Removing intermediate container d9ed01b6ac0a\n",
      " ---> 6bcf71e1ce6d\n",
      "Step 11/14 : COPY main.py /opt/ml/code/main.py\n",
      " ---> 130b1d697577\n",
      "Step 12/14 : COPY train.py /opt/ml/code/train.py\n",
      " ---> c8467444cb41\n",
      "Step 13/14 : COPY handler.py /opt/ml/code/serving/handler.py\n",
      " ---> d35cf5dcb835\n",
      "Step 14/14 : ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]\n",
      " ---> Running in b6b7c3eb85ce\n",
      "Removing intermediate container b6b7c3eb85ce\n",
      " ---> 59a899b9ee2a\n",
      "Successfully built 59a899b9ee2a\n",
      "Successfully tagged iris_model:1.0\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t iris_model:1.0 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Now that we have the algorithm image we can run it to train/deploy a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we need to prepare the dataset\n",
    "You'll see that we're splitting the dataset into training and validation and also saving these two subsets of the dataset into csv files. These files will be then uploaded to an S3 Bucket and shared with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iris_id</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iris_id  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0      0.0                5.1               3.5                1.4   \n",
       "1      0.0                4.9               3.0                1.4   \n",
       "2      0.0                4.7               3.2                1.3   \n",
       "3      0.0                4.6               3.1                1.5   \n",
       "4      0.0                5.0               3.6                1.4   \n",
       "\n",
       "   petal width (cm)  \n",
       "0               0.2  \n",
       "1               0.2  \n",
       "2               0.2  \n",
       "3               0.2  \n",
       "4               0.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf input\n",
    "!mkdir -p input/data/train\n",
    "!mkdir -p input/data/validation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)\n",
    "\n",
    "df = pd.DataFrame(data=dataset, columns=[\"iris_id\"] + iris.feature_names)\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df.insert(0, \"iris_id\", y_train)\n",
    "train_df.to_csv(\"input/data/train/training.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df.insert(0, \"iris_id\", y_test)\n",
    "test_df.to_csv(\"input/data/validation/testing.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Just a basic local test, using the local Docker daemon\n",
    "Here we will simulate SageMaker calling our docker container for training and serving. We'll do that using the built-in Docker Daemon of the Jupyter Notebook Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input/config && mkdir -p input/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/hyperparameters.json\n",
    "{\"max_depth\": 20, \"n_jobs\": 4, \"n_estimators\": 120}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/resourceconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/resourceconfig.json\n",
    "{\"current_host\": \"localhost\", \"hosts\": [\"algo-1-kipw9\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/inputdataconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/inputdataconfig.json\n",
    "{\"train\": {\"TrainingInputMode\": \"File\"}, \"validation\": {\"TrainingInputMode\": \"File\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training mode\n",
      "Training the classifier\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "Score: 0.98\n",
      "CPU times: user 39.9 ms, sys: 19.6 ms, total: 59.5 ms\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!rm -rf model/\n",
    "!mkdir -p model\n",
    "\n",
    "print( \"Training...\")\n",
    "!docker run --rm --name \"my_model\" \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 This is the serving test. It simulates an Endpoint exposed by Sagemaker\n",
    "\n",
    "After you execute the next cell, this Jupyter notebook will freeze. A webservice will be exposed at the port 8080. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Calling MMS with mxnet-model-server. Please move to multi-model-server.\n",
      "2020-09-29 13:14:56,015 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "MMS Home: /usr/local/lib/python3.7/site-packages\n",
      "Current directory: /\n",
      "Temp directory: /tmp\n",
      "Number of GPUs: 0\n",
      "Number of CPUs: 2\n",
      "Max heap size: 988 M\n",
      "Python executable: /usr/local/bin/python\n",
      "Config file: /etc/sagemaker-mms.properties\n",
      "Inference address: http://0.0.0.0:8080\n",
      "Management address: http://0.0.0.0:8080\n",
      "Model Store: /.sagemaker/mms/models\n",
      "Initial Models: ALL\n",
      "Log dir: /logs\n",
      "Metrics dir: /logs\n",
      "Netty threads: 0\n",
      "Netty client threads: 0\n",
      "Default workers per model: 2\n",
      "Blacklist Regex: N/A\n",
      "Maximum Response Size: 6553500\n",
      "Maximum Request Size: 6553500\n",
      "Preload model: false\n",
      "Prefer direct buffer: false\n",
      "2020-09-29 13:14:56,114 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\n",
      "2020-09-29 13:14:56,192 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /tmp/.mms.sock.9000 --handler serving.handler --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /tmp\n",
      "2020-09-29 13:14:56,193 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /tmp/.mms.sock.9000\n",
      "2020-09-29 13:14:56,194 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 31\n",
      "2020-09-29 13:14:56,196 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "2020-09-29 13:14:56,196 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\n",
      "2020-09-29 13:14:56,196 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.7.9\n",
      "2020-09-29 13:14:56,201 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "2020-09-29 13:14:56,232 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2020-09-29 13:14:56,232 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2020-09-29 13:14:56,330 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "Model server started.\n",
      "2020-09-29 13:14:56,342 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2020-09-29 13:14:56,345 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2020-09-29 13:14:56,369 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "2020-09-29 13:14:57,088 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000a-00000000-e00f4ef81f807183-31a21a55\n",
      "2020-09-29 13:14:57,103 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 621\n",
      "2020-09-29 13:14:57,104 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\n",
      "2020-09-29 13:14:57,109 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000a-00000001-2bde36f81f807183-fbe5c779\n",
      "2020-09-29 13:14:57,109 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 631\n",
      "2020-09-29 13:14:57,113 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\n",
      "2020-09-29 13:15:06,663 [INFO ] pool-1-thread-4 ACCESS_LOG - /172.17.0.1:42542 \"GET /ping HTTP/1.1\" 200 24\n",
      "2020-09-29 13:18:02,369 [INFO ] pool-1-thread-5 ACCESS_LOG - /172.17.0.1:42704 \"GET /ping HTTP/1.1\" 200 1\n",
      "2020-09-29 13:26:39,763 [INFO ] pool-1-thread-6 ACCESS_LOG - /172.17.0.1:43480 \"GET /ping HTTP/1.1\" 200 0\n",
      "2020-09-29 13:26:42,436 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "2020-09-29 13:26:42,449 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "2020-09-29 13:26:42,462 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "2020-09-29 13:26:42,540 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 105\n",
      "2020-09-29 13:26:42,541 [INFO ] W-9000-model ACCESS_LOG - /172.17.0.1:43484 \"POST /invocations HTTP/1.1\" 200 109\n",
      "2020-09-29 13:26:42,549 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "2020-09-29 13:26:42,561 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "2020-09-29 13:26:42,575 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "2020-09-29 13:26:42,653 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 105\n",
      "2020-09-29 13:26:42,653 [INFO ] W-9000-model ACCESS_LOG - /172.17.0.1:43488 \"POST /invocations HTTP/1.1\" 200 106\n",
      "2020-09-29 13:26:42,660 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "2020-09-29 13:26:42,673 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "2020-09-29 13:26:42,689 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "2020-09-29 13:26:42,764 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 105\n",
      "2020-09-29 13:26:42,764 [INFO ] W-9000-model ACCESS_LOG - /172.17.0.1:43492 \"POST /invocations HTTP/1.1\" 200 105\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_psposix.py\", line 115, in wait_pid\n",
      "    retpid, status = os.waitpid(pid, flags)\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/main.py\", line 32, in <module>\n",
      "    model_server.start_model_server(handler_service=\"serving.handler\")\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sagemaker_inference/model_server.py\", line 100, in start_model_server\n",
      "    mms_process.wait()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/__init__.py\", line 1281, in wait\n",
      "    self._exitcode = self._proc.wait(timeout)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_pslinux.py\", line 1515, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_pslinux.py\", line 1723, in wait\n",
      "    return _psposix.wait_pid(self.pid, timeout, self._name)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_psposix.py\", line 126, in wait_pid\n",
      "    interval = sleep(interval)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_psposix.py\", line 109, in sleep\n",
      "    _sleep(interval)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --name \"my_model\" \\\n",
    "    -p 8080:8080 \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While the above cell is running, click here [TEST NOTEBOOK](02_Testing%20our%20local%20model%20server.ipynb) to run some tests.\n",
    "\n",
    "> After you finish the tests, press **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3 - Integrated Test: Everything seems ok, now it's time to put all together\n",
    "\n",
    "We'll start by running a local **CodeBuild** test, to check the buildspec and also deploy this image into the container registry. Remember that SageMaker will only see images published to ECR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "repo_name=\"iris-model\"\n",
    "image_tag=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -rf tests && mkdir -p tests\n",
    "!cp handler.py main.py train.py Dockerfile buildspec.yml tests/\n",
    "with open(\"tests/vars.env\", \"w\") as f:\n",
    "    f.write(\"AWS_ACCOUNT_ID=%s\\n\" % account_id)\n",
    "    f.write(\"IMAGE_TAG=%s\\n\" % image_tag)\n",
    "    f.write(\"IMAGE_REPO_NAME=%s\\n\" % repo_name)\n",
    "    f.write(\"AWS_DEFAULT_REGION=%s\\n\" % region)\n",
    "    f.write(\"AWS_ACCESS_KEY_ID=%s\\n\" % credentials.access_key)\n",
    "    f.write(\"AWS_SECRET_ACCESS_KEY=%s\\n\" % credentials.secret_key)\n",
    "    f.write(\"AWS_SESSION_TOKEN=%s\\n\" % credentials.token )\n",
    "    f.close()\n",
    "\n",
    "!cat tests/vars.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!/tmp/aws-codebuild/local_builds/codebuild_build.sh \\\n",
    "    -a \"$PWD/tests/output\" \\\n",
    "    -s \"$PWD/tests\" \\\n",
    "    -i \"samirsouza/aws-codebuild-standard:3.0\" \\\n",
    "    -e \"$PWD/tests/vars.env\" \\\n",
    "    -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have an image deployed in the ECR repo we can also run some local tests using the SageMaker Estimator.\n",
    "\n",
    "> Click on this [TEST NOTEBOOK](03_Testing%20the%20container%20using%20SageMaker%20Estimator.ipynb) to run some tests.\n",
    "\n",
    "> After you finishing the tests, come back to **this notebook** to push the assets to the Git Repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4 - Let's push all the assets to the Git Repo connected to the Build pipeline\n",
    "There is a CodePipeine configured to keep listeining to this Git Repo and start a new Building process with CodeBuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../../../mlops\n",
    "git checkout iris_model\n",
    "cp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - files for building an iris model image\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Alright, now open the AWS console and go to the **CodePipeline** dashboard. Look for a pipeline called **mlops-iris-model**. This pipeline will deploy the final image to an ECR repo. When this process finishes, open the **Elastic Compute Registry** dashboard, in the AWS console, and check if you have an image called **iris-model:latest**. If yes, you can go to the next exercise. If not, wait a little more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
